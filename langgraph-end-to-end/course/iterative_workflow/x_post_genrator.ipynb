{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2ff0d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(53832) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (0.5.4)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph) (0.3.69)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph) (0.1.74)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: anyio in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(53843) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (2.1.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-google-genai) (0.3.69)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-google-genai) (2.11.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.31.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/comida/ai-learning/.venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph\n",
    "!pip install langchain-google-genai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f16dc066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_core.messages  import SystemMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dc43456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/comida/ai-learning/.venv/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "Python(53958) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/Users/comida/ai-learning/.venv/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "Python(53979) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/Users/comida/ai-learning/.venv/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "Python(54004) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "generator_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "evaluator_llm= ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "optimizer_llm= ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2994b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"need_improvment\"]= Field(..., description=\"Final evalutaion\")\n",
    "    feedback: str =Field(...,description=\"feedback of the tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3705f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm =evaluator_llm.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbc442e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state\n",
    "class TweetState(TypedDict):\n",
    "    topic :str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\",\"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c8f9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "    #prompt \n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "Rules:\n",
    "- Do NOT use question-answer format.\n",
    "- Max 280 characters.\n",
    "- Use observational humor, irony, sarcasm, or cultural references.\n",
    "- Think in meme logic, punchlines, or relatable takes.\n",
    "- Use simple, day to day english\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    #send to generator llm \n",
    "    response=generator_llm.invoke(messages).content\n",
    "\n",
    "    #return state\n",
    "    return { \"tweet\": response}\n",
    "\n",
    "def evaluate_tweet(state: TweetState):\n",
    "    #prompt\n",
    "    messages=[\n",
    "       SystemMessage(\n",
    "    content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets harshly.\"\n",
    "),\n",
    "HumanMessage(\n",
    "    content=f\"\"\"\n",
    "Evaluate the following tweet:\n",
    "\n",
    "Tweet: \"{state['tweet']}\"\n",
    "\n",
    "Use the criteria below to evaluate the tweet:\n",
    "\n",
    "1. Originality Is this fresh, or have you seen it a hundred times before?\n",
    "2. Humor  Did it genuinely make you smile, laugh, or chuckle?\n",
    "3. Punchiness  Is it short, sharp, and scroll-stopping?\n",
    "4. Virality Potential  Would people retweet or share it?\n",
    "5. Format Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "Auto-reject if:\n",
    "- It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "- It exceeds 280 characters\n",
    "- It reads like a traditional setup-punchline joke\n",
    "- Don’t end with generic, throwaway, or deflating lines that weaken the humor (e.g., “Masterpieces are overrated.”)\n",
    "\n",
    "### Respond ONLY in structured format:\n",
    "- evaluation: \"approved\" or \"needs_improvement\"\n",
    "- feedback: One paragraph explaining the strengths and weaknesses\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "    #send to generator llm\n",
    "    response =structured_evaluator_llm.invoke(messages)\n",
    "\n",
    "    return {'evaluation': response.evaluation, \"feedback\": response.feedback}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def optimized_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Improve the tweet based on this feedback:\n",
    "\"{state['feedback']}\"\n",
    "\n",
    "Topic: \"{state['topic']}\"\n",
    "Original Tweet:\n",
    "{state['tweet']}\n",
    "\n",
    "Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    response= optimizer_llm.invoke(messages).content\n",
    "    iteration= state['iteration']+1\n",
    "\n",
    "    return {'tweet': response, 'iteration': iteration }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b354d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation']=='approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a141e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1158b0690>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph =StateGraph(TweetState)\n",
    "\n",
    "graph.add_node(\"generate\", generate_tweet)\n",
    "graph.add_node(\"evaluate\", evaluate_tweet)\n",
    "graph.add_node(\"optimize\", optimized_tweet)\n",
    "\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "graph.add_conditional_edges('evaluate',route_evaluation, {'evaluate': END, 'needs_improvement': 'optimize'})\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "\n",
    "workflow=graph.compile()\n",
    "\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b48f5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised PermissionDenied: 403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"method\"\n",
      "  value: \"google.ai.generativelanguage.v1beta.GenerativeService.GenerateContent\"\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "PermissionDenied",
     "evalue": "403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.GenerativeService.GenerateContent\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDenied\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m intial_state={\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mindian railway\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33miteration\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_iterations\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m\n\u001b[32m      5\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mgenerate_tweet\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m     messages = [\n\u001b[32m      4\u001b[39m         SystemMessage(content=\u001b[33m\"\u001b[39m\u001b[33mYou are a funny and clever Twitter/X influencer.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m         HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     15\u001b[39m     ]\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m#send to generator llm \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     response=\u001b[43mgenerator_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m.content\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m#return state\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m { \u001b[33m\"\u001b[39m\u001b[33mtweet\u001b[39m\u001b[33m\"\u001b[39m: response}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1334\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1330\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1331\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1332\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1441\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1415\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1416\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1427\u001b[39m     **kwargs: Any,\n\u001b[32m   1428\u001b[39m ) -> ChatResult:\n\u001b[32m   1429\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1430\u001b[39m         messages,\n\u001b[32m   1431\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1439\u001b[39m         **kwargs,\n\u001b[32m   1440\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:231\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    224\u001b[39m params = (\n\u001b[32m    225\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    230\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:222\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai-learning/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mPermissionDenied\u001b[39m: 403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.GenerativeService.GenerateContent\"\n}\n]",
      "During task with name 'generate' and id '7337c568-7580-5269-f15e-694c364f0b7d'"
     ]
    }
   ],
   "source": [
    "intial_state={\n",
    "    \"topic\": \"indian railway\",\n",
    "    \"iteration\": 1,\n",
    "    \"max_iterations\": 5\n",
    "}\n",
    "\n",
    "workflow.invoke(intial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
